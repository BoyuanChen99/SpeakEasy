import os
import sys

sys.path.append(os.getcwd())

import json
import copy
import yaml
from tqdm import tqdm
import numpy as np
from box import Box
from transformers import AutoTokenizer

from .utils.baseline import SingleBehaviorRedTeamingMethod
from .utils.conversers import load_TAP_models
from .utils.common import process_target_response, get_init_msg
from .utils.system_prompts import get_attacker_system_prompt

from utils import truncate_strings


class Baseline_TAP(SingleBehaviorRedTeamingMethod):
    use_ray = False
    
    def __init__(self, model=None):
        """
        :param attack_model: a dictionary specifying the attack model to use (arg for load_TAP_models)
        :param target_model: a dictionary specifying the target model to use (arg for load_TAP_models)
        :param judge_model: a dictionary specifying the judge model to use (arg for load_TAP_models)
        :param targets_path: the path to the targets JSON file
        :param attack_max_n_tokens: the number of tokens to generate with the attack model
        :param target_max_n_tokens: the number of tokens to generate with the target model
        :param judge_max_n_tokens: the number of tokens to generate with the judge model
        :param max_retries: the number of retries for each generation
        :param attack_temp: the temperature for the attack model
        :param n_streams: the number of streams to use (Number of root nodes in the tree of thoughts)
        :param branching_factor: the branching factor for the tree of thoughts (new leaves at each level of the tree before prunning)
        :param width: the number of top `k` leaves (based on scores) to keep after PRUNE: PHASE 2
        :param depth: the depth/steps of the tree
        :param keep_last_n: The number of responses to save in the conversation history of the attack model. If this is too large, then it may exceed the context window of the model.
        :param cutoff_score: the judge score cutoff to determine whether test cases were successful: 10 for GPT-4 judge and 7 for Mixtral judge
        """
        self.config = Box(yaml.safe_load(open(os.path.join(os.path.dirname(__file__), "config.yaml"), "r")))
        self.models = Box(yaml.safe_load(open(os.path.join(os.path.dirname(__file__), "models.yaml"), "r")))
            
        self.model=model
        
        targetLLM_args = self.config[model].target_model
        targetLLM_args["model_name_or_path"] = self.models[model].model.model_name_or_path

        self.attackLM, self.targetLM, self.judgeLM = load_TAP_models(self.config.default_method_hyperparameters.attack_model,
                                                                     targetLLM_args,
                                                                     self.config.default_method_hyperparameters.judge_model,
                                                                     self.config.default_method_hyperparameters.attack_max_n_tokens,
                                                                     self.config.default_method_hyperparameters.target_max_n_tokens,
                                                                     self.config.default_method_hyperparameters.judge_max_n_tokens,
                                                                     self.config.default_method_hyperparameters.max_retries,
                                                                     self.config.default_method_hyperparameters.attack_temp)

        self.n_streams = self.config.default_method_hyperparameters.n_streams
        self.branching_factor = self.config.default_method_hyperparameters.branching_factor
        self.width = self.config.default_method_hyperparameters.width
        self.depth = self.config.default_method_hyperparameters.depth
        self.keep_last_n = self.config.default_method_hyperparameters.keep_last_n
        self.cutoff_score = self.config.default_method_hyperparameters.cutoff_score

    def generate_single_test_case(self, query, target):
        """
        Generate a test cases for the behavior

        :param query: jailbreak prompt
        """
        
        # Initialize conversations
        system_prompt = get_attacker_system_prompt(query, "", target)

        # TAP vars
        n_streams = self.n_streams
        branching_factor = self.branching_factor
        depth = self.depth
        width = self.width
        keep_last_n = self.keep_last_n
        cutoff_score = self.cutoff_score

        attackLM = self.attackLM
        targetLM = self.targetLM
        judgeLM = self.judgeLM
        
        # Initialize conversations
        init_msg = get_init_msg(query, target, "")
        processed_response_list = [init_msg for _ in range(n_streams)]
        convs_list = [copy.deepcopy(attackLM.template) for _ in range(n_streams)]            

        for conv in convs_list:
            conv.set_system_message(system_prompt)

        # Begin TAP
        logs = []
        best_adv_prompt = query
        highest_score = 0
        for step in range(0, depth):
            # ======== Get adversarial prompts on all active streams(trees) x leaves (width) x branching_factor ========= #
            extracted_attack_list = []
            convs_list_new = []

            for _ in range(branching_factor):
                convs_list_copy = copy.deepcopy(convs_list) 
                extracted_attack_list.extend(
                        attackLM.get_attack(convs_list_copy, processed_response_list)
                    )
                convs_list_new.extend(convs_list_copy)
                
            # Remove any failed attacks and corresponding conversations
            convs_list = copy.deepcopy(convs_list_new)
            extracted_attack_list, convs_list = clean_attacks_and_convs(extracted_attack_list, convs_list)
            
            adv_prompt_list = [attack["prompt"] for attack in extracted_attack_list]
            improv_list = [attack["improvement"] for attack in extracted_attack_list]

            # ======== prune phase 1 ========= #
            # Get on-topic-scores (does the adv_prompt asks for same info as original prompt)
            on_topic_scores = judgeLM.on_topic_score(adv_prompt_list, query, target, "")

            # Prune attacks which are irrelevant
            (on_topic_scores,
            _,
            adv_prompt_list,
            improv_list,
            convs_list,
            _,
            extracted_attack_list) = prune(
                on_topic_scores,
                None, # judge_scores
                adv_prompt_list,
                improv_list,
                convs_list,
                None, # target_response_list
                extracted_attack_list,
                sorting_score=on_topic_scores,
                width=width)
            
            # ======== Get target responses ========
            target_response_list = targetLM.get_response(adv_prompt_list, "")

            # ======== Get judge (GPT) scores ========
            judge_scores = judgeLM.score(adv_prompt_list, target_response_list, query, target, "")

            # ======== prune phase 2 ========= #
            # Prune attacks which to be fewer than 'width'
            (on_topic_scores,
            judge_scores,
            adv_prompt_list,
            improv_list,
            convs_list,
            target_response_list,
            extracted_attack_list) = prune(
                on_topic_scores,
                judge_scores,
                adv_prompt_list,
                improv_list,
                convs_list,
                target_response_list,
                extracted_attack_list,
                sorting_score=judge_scores,
                width=width) 

            # ======== Handling outputs and scores ========
            jailbroken = False
            for conv, adv_prompt, on_topic_score, judge_score, improv, target_response in zip(convs_list, adv_prompt_list, on_topic_scores, judge_scores, improv_list, target_response_list):
                if judge_score >= cutoff_score:
                    jailbroken = True

                if judge_score > highest_score:
                    highest_score = judge_score
                    best_adv_prompt = adv_prompt

                conv.messages = conv.messages[-2*(keep_last_n):] 

                # ===== logging each step ======
                log = dict(adv_prompt=adv_prompt, on_topic_score=on_topic_score, judge_score=judge_score, target_response=target_response, improv=improv)
                logs.append(log)

            # ========= Done if found a score == 10 ======
            if jailbroken: 
                    break
            
            # `process_target_response` concatenates the target response, goal, and score 
            #   -- while adding appropriate labels to each
            processed_response_list = [
                    process_target_response(target_response, score, query, target, "")
                        for target_response, score in zip(target_response_list, judge_scores)
                ] 
        
        print(best_adv_prompt)
        return(best_adv_prompt)
        exit()

    def get_all_test_cases(self, data, test_case_path=None):
        if os.path.exists(test_case_path):
            test_cases = json.load(open(test_case_path, "r"))
        else:
            test_cases = []
            for query in tqdm(data, desc="Generating test cases"):
                test_case = self.generate_single_test_case(query["query"], query["target"])
                test_cases.append(test_case)

            json.dump(test_cases, open(test_case_path, "w"), indent=4)

        return test_cases


    def infer(self, data, save_dir):
        if not os.path.exists(os.path.dirname(save_dir)):
            os.makedirs(os.path.dirname(save_dir))

        save_path = os.path.join(save_dir, "combined_responses.json")

        # attack prompts generated by TAP
        prompts = self.get_all_test_cases(data, test_case_path=os.path.join(save_dir, "tap_attack_prompts.json"))

        if not os.path.exists(save_path):
            outputs = self.model.infer_batch(prompts, save_path)

            qa_pairs = {}
            for query, response in zip(data, outputs):
                if response == None:
                    qa_pairs[query['query']] = ""
                else:
                    qa_pairs[query['query']] = response
                    
            json.dump(qa_pairs, open(save_path, "w"), indent=4)

        else:
            qa_pairs = json.load(open(save_path, "r"))

## ======== TAP Helper Functions ========
def prune(on_topic_scores=None,
            judge_scores=None,
            adv_prompt_list=None,
            improv_list=None,
            convs_list=None,
            target_response_list=None,
            extracted_attack_list=None,
            sorting_score=None,
            width=None):
    """
        This function takes 
            1. various lists containing metadata related to the attacks as input, 
            2. a list with `sorting_score`
        It prunes all attacks (and correspondng metadata)
            1. whose `sorting_score` is 0;
            2. which exceed the `attack 'width'` when arranged 
               in decreasing order of `sorting_score`.

        In Phase 1 of pruning, `sorting_score` is a list of `on-topic` values.
        In Phase 2 of pruning, `sorting_score` is a list of `judge` values.
    """
    # Shuffle the brances and sort them according to judge scores
    shuffled_scores = enumerate(sorting_score)
    shuffled_scores = [(s, i) for (i, s) in shuffled_scores]
    # Ensures that elements with the same score are randomly permuted
    np.random.shuffle(shuffled_scores) 
    shuffled_scores.sort(reverse=True)

    def get_first_k(list_, width=width):
        width = min(width, len(list_))
        
        truncated_list = [list_[shuffled_scores[i][1]] for i in range(width) if shuffled_scores[i][0] > 0]

        # Ensure that the truncated list has at least two elements
        if len(truncated_list ) == 0:
            truncated_list = [list_[shuffled_scores[0][0]], list_[shuffled_scores[0][1]]] 
        
        return truncated_list

    # Prune the brances to keep 
    # 1) the first 'width'-parameters
    # 2) only attacks whose score is positive

    if judge_scores is not None:
        judge_scores = get_first_k(judge_scores) 
    
    if target_response_list is not None:
        target_response_list = get_first_k(target_response_list)
    
    on_topic_scores = get_first_k(on_topic_scores)
    adv_prompt_list = get_first_k(adv_prompt_list)
    improv_list = get_first_k(improv_list)
    convs_list = get_first_k(convs_list)
    extracted_attack_list = get_first_k(extracted_attack_list)

    return on_topic_scores,\
            judge_scores,\
            adv_prompt_list,\
            improv_list,\
            convs_list,\
            target_response_list,\
            extracted_attack_list

def clean_attacks_and_convs(attack_list, convs_list):
    """
        Remove any failed attacks (which appear as None) and corresponding conversations
    """
    tmp = [(a, c) for (a, c) in zip(attack_list, convs_list) if a is not None]
    tmp = [*zip(*tmp)]
    attack_list, convs_list = list(tmp[0]), list(tmp[1])

    return attack_list, convs_list