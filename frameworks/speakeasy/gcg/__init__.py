import os
import json
import pandas as pd 

from tqdm import tqdm
from munch import Munch

from transformers import AutoTokenizer

from translation import get_translator
from resp_select_models import get_model
from utils import (
    extract_subquery,
    reduce_repeated_phrases,
    contains_refusal_words,
    truncate_strings,
    LANGUAGE_LIST,
)


class SpeakEasy_GCG:
    def __init__(self, model, device):
        self.model = model

        # Load config files
        self.config = Munch.fromYAML(
            open(os.path.join(os.path.dirname(__file__), "config.yaml"), "r")
        )

        # Get modules based on config
        self.device=device
        self.translator = get_translator(self.config.translator)
        self.max_tokens = self.config.max_tokens

    def infer(self, data, save_dir):
        """
        Infers responses for a list of queries, translating sub-queries into multiple languages,
        processing them through a model, and combining the best responses.

        Args:
            queries (list of str): A list of queries to process.
            save_dir (str): Directory to save intermediate and final JSON files.

        Steps:
            1. Generate sub-queries:
                - Check if translated sub-queries exist; if not, generate and save them.
                - Translate sub-queries into multiple languages and save them.
            2. Answer sub-questions:
                - Check if English responses exist; if not, generate and save them.
                - Translate responses back to English and save them.
            3. Combine responses:
                - Filter responses to exclude refusals.
                - Score responses and save the scored responses.
                - Select the best response for each query based on the highest score.
                - Save the combined best responses.

        Returns:
            None: The function saves intermediate and final results as JSON files in the specified directory.
        """
        if not os.path.exists(os.path.dirname(save_dir)):
            os.makedirs(os.path.dirname(save_dir))

        ###########################
        # 1. GENERATE SUB-QUERIES #
        ###########################
        print("Step 1: Get multilingual subqueries")
        save_path = os.path.join(save_dir, "subqueries.json")

        if not os.path.exists(save_path):
        # Formatting the in-context examples
            icl_examples_dict = dict(self.config.icl_examples)
            formatted_icl_examples = ""
            for key, value in icl_examples_dict.items():
                formatted_icl_examples += f"{key}:\n" + "\n".join([f" {item}" for item in value]) + "\n"

            prompts = [
                self.config.prompts.generate_subqueries.format(
                    self.config.num_subqueries, instance["query"], formatted_icl_examples
                )
                for instance in data
            ]
            outputs = self.model.infer_batch(prompts, save_path)

            # Extract generated subqueries and populate subquery dictionary
            outputs = [
                extract_subquery(output, self.config.num_subqueries)
                for output in outputs
            ]

            subqueries = {
                query: cleaned_output
                for query, cleaned_output in zip(
                    [instance["query"] for instance in data], outputs
                )
            }

            # Add GCG suffix to the translated subquery
            if "sorry" in save_dir:
                adversarial_suffix = self.config.adversarial_suffix_sorrybench
            elif 'med' in save_dir:
                adversarial_suffix = self.config.adversarial_suffix_med
            elif 'harm' in save_dir:
                adversarial_suffix = self.config.adversarial_suffix_harmbench
            elif 'adv' in save_dir:
                adversarial_suffix = self.config.adversarial_suffix_advbench

            # Translate subqueries into each language in LANG_LIST
            translated_subqueries = {
                query: {
                    sub_query: {
                        lang: (
                            f"{sub_query} Keep your response within 120 words. {adversarial_suffix} "
                            if lang == "en"
                            else f'{self.translator.translate_multilingual(sub_query + " Keep your response within 120 words.", source="en",target=lang)} {adversarial_suffix}' 
                        )
                        for lang in LANGUAGE_LIST.values()
                    }
                    for sub_query in sub_query_list
                }
                for query, sub_query_list in subqueries.items()
            }

            # Save translated sub queries
            json.dump(
                translated_subqueries,
                open(save_path, "w", encoding="utf-8"),
                ensure_ascii=False,
                indent=4,
            )
        else:
            translated_subqueries = json.load(open(save_path, "r"))

        ###########################
        # 2. ANSWER SUB-QUESTIONS #
        ###########################
        print("Step 2: Answer multilingual subqueries")
        save_path = os.path.join(save_dir, "responses_en.json")

        if not os.path.exists(save_path):
            # Creating responses_translated using dictionary comprehensions
            responses_translated = {
                query: {
                    sub_query: {
                        lang: translation for lang, translation in translations.items()
                    }
                    for sub_query, translations in subqueries.items()
                }
                for query, subqueries in translated_subqueries.items()
            }

            # Flattening translations and collecting corresponding keys
            translations_list = [
                translation
                for subqueries in translated_subqueries.values()
                for translations in subqueries.values()
                for translation in translations.values()
            ]

            keys_list = [
                (query, sub_query, lang)
                for query, subqueries in translated_subqueries.items()
                for sub_query, translations in subqueries.items()
                for lang in translations.keys()
            ]

            # Processing translations using model
            log_save_path = save_path.replace("_en", "_multilingual")
            
            outputs = self.model.infer_batch(translations_list, log_save_path)

            # Updating responses_translated with processed values
            for (query, sub_query, lang), processed_value in zip(keys_list, outputs):
                responses_translated[query][sub_query][lang] = processed_value

            # Translate responses into English
            def clean_and_translate(text, source_lang, target_lang="en"):
                cleaned_text = reduce_repeated_phrases(text)

                if source_lang == "en" or text == "":
                    return text
                else:
                    translated_text = self.translator.translate_to_english(
                        sentence=cleaned_text, 
                        source=source_lang, 
                        target=target_lang,
                        save_dir=save_path.replace("_en", "_translate")
                    )
                    return translated_text
            
            responses_en = {}

            for query, subqueries in tqdm(responses_translated.items(), desc="Translation", ncols=100, leave=False):
                responses_en[query] = {}
                
                for sub_query, responses in subqueries.items():
                    responses_en[query][sub_query] = {}
                    
                    for lang, response in responses.items():
                        responses_en[query][sub_query][lang] = clean_and_translate(response, lang)


            # Save English responses to a JSON file in save_dir
            json.dump(
                responses_en,
                open(save_path, "w", encoding="utf-8"),
                ensure_ascii=False,
                indent=4,
            )

        else:
            responses_en = json.load(open(save_path, "r"))

        ########################
        # 3. COMBINE RESPONSES #
        ########################
        print("Step 3: Select and combine best queries")
        save_path = os.path.join(save_dir, "responses_with_reward.json")

        # Score each response
        if not os.path.exists(save_path):
            resp_select_model = get_model(self.config.resp_select_model, device=self.device)
            responses_with_reward = resp_select_model.get_reward(responses_en)

            # Save responses with rewards to a JSON file in save_dir
            json.dump(responses_with_reward, open(save_path, "w"), indent=4)
        else:
            responses_with_reward = json.load(open(save_path, "r"))

    
        # Select response with highest score
        combined_responses = {
            query: "".join(
                max(responses.items(), key=lambda item: item[1]["score"])[1]["response"]
                for responses in subqueries.values()
            )
            for query, subqueries in responses_with_reward.items()
        }

        json.dump(
            combined_responses,
            open(os.path.join(save_dir, "combined_responses.json"), "w"),
            indent=4,
        )
